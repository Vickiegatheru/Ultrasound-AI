{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!unzip -q archive.zip -d dataset\n",
        "\n",
        "print(\"Unzipping complete. Here is the folder structure:\")\n",
        "!ls dataset"
      ],
      "metadata": {
        "id": "57Fz0kLaA9Co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4qku9oKKZjT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Settings\n",
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "IMG_CHANNELS = 3\n",
        "\n",
        "print(\"Libraries imported.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(root_path):\n",
        "    images = []\n",
        "    masks = []\n",
        "\n",
        "    print(\"Scanning for images and masks...\")\n",
        "\n",
        "    for root, dirs, files in os.walk(root_path):\n",
        "        for file in files:\n",
        "            # We look for original images (not masks) first\n",
        "            if 'mask' not in file and file.lower().endswith('.png'):\n",
        "\n",
        "                # Construct the path to the image\n",
        "                img_path = os.path.join(root, file)\n",
        "\n",
        "                # Construct the expected path to the mask\n",
        "                # (Assumes mask has same name but adds '_mask')\n",
        "                mask_name = file.replace('.png', '_mask.png')\n",
        "                mask_path = os.path.join(root, mask_name)\n",
        "\n",
        "                # Only proceed if the mask actually exists\n",
        "                if os.path.exists(mask_path):\n",
        "                    # Load and Resize Image\n",
        "                    img = cv2.imread(img_path)\n",
        "                    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\n",
        "                    # Load and Resize Mask (Load as grayscale)\n",
        "                    mask = cv2.imread(mask_path, 0)\n",
        "                    mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT))\n",
        "                    mask = np.expand_dims(mask, axis=-1) # Add depth for AI processing\n",
        "\n",
        "                    images.append(img)\n",
        "                    masks.append(mask)\n",
        "\n",
        "    return np.array(images), np.array(masks)\n",
        "\n",
        "# Load the data from the folder we created in Cell 1\n",
        "X, y = load_data('./dataset')\n",
        "\n",
        "print(f\"Successfully loaded {len(X)} image/mask pairs.\")\n",
        "\n",
        "# Normalize the pixel data (0 to 1 range)\n",
        "X = X / 255.0\n",
        "y = y / 255.0 # Masks become 0 or 1\n",
        "\n",
        "# Split into Training (90%) and Test (10%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "print(\"Data ready for training.\")"
      ],
      "metadata": {
        "id": "I7FHP8plGZVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # --- ENCODER (Contracting Path) ---\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', padding='same')(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', padding='same')(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', padding='same')(c3)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', padding='same')(p3)\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', padding='same')(c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "\n",
        "    # --- BOTTLENECK ---\n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', padding='same')(p4)\n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', padding='same')(c5)\n",
        "\n",
        "    # --- DECODER (Expansive Path) ---\n",
        "    u6 = UpSampling2D((2, 2))(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', padding='same')(u6)\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', padding='same')(c6)\n",
        "\n",
        "    u7 = UpSampling2D((2, 2))(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', padding='same')(u7)\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', padding='same')(c7)\n",
        "\n",
        "    u8 = UpSampling2D((2, 2))(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', padding='same')(u8)\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', padding='same')(c8)\n",
        "\n",
        "    u9 = UpSampling2D((2, 2))(c8)\n",
        "    u9 = concatenate([u9, c1])\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', padding='same')(u9)\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', padding='same')(c9)\n",
        "\n",
        "    # Output Layer: Sigmoid gives a probability (0-1) for every pixel\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = build_unet((IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS))\n",
        "print(\"Model built successfully.\")"
      ],
      "metadata": {
        "id": "DxW19_vyGdmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting training...\")\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_split=0.1,\n",
        "                    batch_size=16,\n",
        "                    epochs=15,\n",
        "                    verbose=1)\n",
        "print(\"Training finished.\")"
      ],
      "metadata": {
        "id": "yxbo27U9GkjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Make predictions\n",
        "preds = model.predict(X_test, verbose=0)\n",
        "# Convert probabilities to strictly 0 or 1 (Tumor or No Tumor)\n",
        "preds_thresholded = (preds > 0.5).astype(np.uint8)\n",
        "\n",
        "# 2. Function to plot\n",
        "def plot_results(num_samples=3):\n",
        "    for i in range(num_samples):\n",
        "        ix = np.random.randint(0, len(X_test)) # Pick random image\n",
        "\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        # Plot Original Ultrasound\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(X_test[ix])\n",
        "        plt.title(\"Original Ultrasound\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Plot True Mask (Ground Truth)\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(y_test[ix].squeeze(), cmap='gray')\n",
        "        plt.title(\"Actual Tumor (Doctor)\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Plot AI Prediction\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(preds_thresholded[ix].squeeze(), cmap='gray')\n",
        "        plt.title(\"AI Prediction\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "# 3. Show the plots\n",
        "plot_results()"
      ],
      "metadata": {
        "id": "OHVWSlcMGp3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uWF-hpbDGwSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell first deletes any old failed attempts to keep your workspace clean.\n",
        "\n",
        "It unzips archive.zip into a folder called dataset_intense.\n",
        "\n",
        "It checks the file size first to warn you if the upload failed again."
      ],
      "metadata": {
        "id": "Q5u0NP5vJ77K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# 1. Clean up previous runs (Optional but recommended)\n",
        "if os.path.exists('dataset_intense'):\n",
        "    shutil.rmtree('dataset_intense')\n",
        "\n",
        "# 2. Check if archive.zip exists and has data\n",
        "file_path = 'archive.zip'\n",
        "if not os.path.exists(file_path):\n",
        "    print(\"ERROR: 'archive.zip' not found. Please upload it to the Files tab on the left.\")\n",
        "elif os.path.getsize(file_path) < 1000:\n",
        "    print(\"ERROR: 'archive.zip' is too small (looks empty). Please delete and re-upload.\")\n",
        "else:\n",
        "    # 3. Unzip\n",
        "    print(\"Unzipping archive.zip...\")\n",
        "    !unzip -q archive.zip -d dataset_intense\n",
        "    print(\"Unzipping complete.\")\n",
        "\n",
        "    # 4. Verify what we have\n",
        "    print(\"\\nRoot folder contents:\")\n",
        "    !ls dataset_intense"
      ],
      "metadata": {
        "id": "RMejZmluKO6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are adding BatchNormalization, Dropout, and Callbacks to our imports. These are the tools for the \"intense\" training."
      ],
      "metadata": {
        "id": "qLU5uMNkMp_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Configuration\n",
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "IMG_CHANNELS = 3\n",
        "\n",
        "print(\"Libraries imported. GPU Available: \", len(tf.config.list_physical_devices('GPU')) > 0)"
      ],
      "metadata": {
        "id": "372jRigRMsnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Smart Data Loading\n",
        "Notes for Colab:\n",
        "\n",
        "This is the same robust loader as before. It scans the dataset_intense folder.\n",
        "\n",
        "It normalizes images (dividing by 255) immediately to save RAM."
      ],
      "metadata": {
        "id": "VmSh2druMyci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(root_path):\n",
        "    images = []\n",
        "    masks = []\n",
        "\n",
        "    print(\"Scanning for data...\")\n",
        "    for root, dirs, files in os.walk(root_path):\n",
        "        for file in files:\n",
        "            if 'mask' not in file and file.lower().endswith('.png'):\n",
        "                img_path = os.path.join(root, file)\n",
        "                mask_name = file.replace('.png', '_mask.png')\n",
        "                mask_path = os.path.join(root, mask_name)\n",
        "\n",
        "                if os.path.exists(mask_path):\n",
        "                    # Load Image\n",
        "                    img = cv2.imread(img_path)\n",
        "                    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
        "                    images.append(img)\n",
        "\n",
        "                    # Load Mask (Grayscale)\n",
        "                    mask = cv2.imread(mask_path, 0)\n",
        "                    mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT))\n",
        "                    mask = np.expand_dims(mask, axis=-1)\n",
        "                    masks.append(mask)\n",
        "\n",
        "    return np.array(images), np.array(masks)\n",
        "\n",
        "# Load data\n",
        "X, y = load_data('./dataset_intense')\n",
        "\n",
        "# Check if data loaded correctly\n",
        "if len(X) == 0:\n",
        "    print(\"ERROR: No images found. Check your zip file structure.\")\n",
        "else:\n",
        "    print(f\"Loaded {len(X)} images and masks.\")\n",
        "\n",
        "    # Normalize\n",
        "    X = X / 255.0\n",
        "    y = y / 255.0\n",
        "\n",
        "    # Split Data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "    print(\"Data normalized and split ready for intense training.\")"
      ],
      "metadata": {
        "id": "Cy-r2yiXM34Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filters: We start at 32 filters (instead of 16) for deeper feature detection.\n",
        "\n",
        "Dropout (0.2): Discards 20% of neurons randomly to prevent memorization.\n",
        "\n",
        "BatchNormalization: Added after every convolution block. This stabilizes the math inside the network, allowing it to learn much faster without getting \"confused.\""
      ],
      "metadata": {
        "id": "p7NCsDvqM-ss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_unet_model(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS):\n",
        "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "\n",
        "    # --- Contraction Path (Encoder) ---\n",
        "    c1 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
        "    c1 = BatchNormalization()(c1)\n",
        "    c1 = Dropout(0.1)(c1)\n",
        "    c1 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "    c1 = BatchNormalization()(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "    c2 = BatchNormalization()(c2)\n",
        "    c2 = Dropout(0.2)(c2)\n",
        "    c2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "    c2 = BatchNormalization()(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "    c3 = BatchNormalization()(c3)\n",
        "    c3 = Dropout(0.2)(c3)\n",
        "    c3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "    c3 = BatchNormalization()(c3)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "    c4 = BatchNormalization()(c4)\n",
        "    c4 = Dropout(0.2)(c4)\n",
        "    c4 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "    c4 = BatchNormalization()(c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "\n",
        "    # --- Bottleneck ---\n",
        "    c5 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "    c5 = BatchNormalization()(c5)\n",
        "    c5 = Dropout(0.3)(c5)\n",
        "    c5 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "    c5 = BatchNormalization()(c5)\n",
        "\n",
        "    # --- Expansive Path (Decoder) ---\n",
        "    u6 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "    c6 = BatchNormalization()(c6)\n",
        "    c6 = Dropout(0.2)(c6)\n",
        "    c6 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        "    c6 = BatchNormalization()(c6)\n",
        "\n",
        "    u7 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "    c7 = BatchNormalization()(c7)\n",
        "    c7 = Dropout(0.2)(c7)\n",
        "    c7 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        "    c7 = BatchNormalization()(c7)\n",
        "\n",
        "    u8 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "    c8 = BatchNormalization()(c8)\n",
        "    c8 = Dropout(0.1)(c8)\n",
        "    c8 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
        "    c8 = BatchNormalization()(c8)\n",
        "\n",
        "    u9 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    c9 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "    c9 = BatchNormalization()(c9)\n",
        "    c9 = Dropout(0.1)(c9)\n",
        "    c9 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
        "    c9 = BatchNormalization()(c9)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = simple_unet_model(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
        "print(\"Intense Model Built.\")"
      ],
      "metadata": {
        "id": "BUYi4icYND10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EarlyStopping: If the model stops improving for 10 epochs, training stops automatically. This saves time and prevents overfitting.\n",
        "\n",
        "ReduceLROnPlateau: If the model gets \"stuck\", this lowers the learning rate (makes the steps smaller) to help it find the optimal solution.\n",
        "\n",
        "Epochs: Set to 50. Don't worry, EarlyStopping will cut it short if it finishes early."
      ],
      "metadata": {
        "id": "J75U2XDwNGrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "early_stopper = EarlyStopping(patience=10, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1)\n",
        "\n",
        "print(\"Starting intense training...\")\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=16,\n",
        "                    epochs=50,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[early_stopper, reduce_lr])\n",
        "\n",
        "print(\"Training finished.\")"
      ],
      "metadata": {
        "id": "39JJ74ASNPHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This visualizer creates a large, clear comparison.\n",
        "\n",
        "It converts the AI's \"probability map\" into a crisp Black/White mask using a 0.5 threshold."
      ],
      "metadata": {
        "id": "O3BZMvHHNj3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict\n",
        "preds_test = model.predict(X_test, verbose=1)\n",
        "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
        "\n",
        "def plot_random_sample():\n",
        "    ix = np.random.randint(0, len(X_test))\n",
        "\n",
        "    fig, ax = plt.subplots(1, 3, figsize=(20, 8))\n",
        "\n",
        "    # Original\n",
        "    ax[0].imshow(X_test[ix])\n",
        "    ax[0].set_title(\"Ultrasound\", fontsize=16)\n",
        "    ax[0].axis('off')\n",
        "\n",
        "    # Ground Truth\n",
        "    ax[1].imshow(y_test[ix].squeeze(), cmap='gray')\n",
        "    ax[1].set_title(\"Doctor's Label (Ground Truth)\", fontsize=16)\n",
        "    ax[1].axis('off')\n",
        "\n",
        "    # Prediction\n",
        "    ax[2].imshow(preds_test_t[ix].squeeze(), cmap='gray')\n",
        "    ax[2].set_title(\"AI Prediction\", fontsize=16)\n",
        "    ax[2].axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Run this line multiple times to see different images\n",
        "plot_random_sample()\n",
        "plot_random_sample()"
      ],
      "metadata": {
        "id": "QNMuSLfwNpjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model architecture and weights\n",
        "model.save('ultrasound_unet_model.h5')\n",
        "print(\"Model saved as 'ultrasound_unet_model.h5'\")\n",
        "\n",
        "# Download it to your local computer (Optional but recommended)\n",
        "from google.colab import files\n",
        "files.download('ultrasound_unet_model.h5')"
      ],
      "metadata": {
        "id": "M78WyIExOYOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate Medical Metrics (For your Report)\n",
        "Standard \"Accuracy\" is misleading in cancer detection because most of the image is black background. If the AI predicts \"all black,\" it might still get 90% accuracy but miss the tumor entirely.\n",
        "\n",
        "You need Dice Coefficient and IoU (Intersection over Union). These measure the overlap between the Doctor's mask and the AI's mask."
      ],
      "metadata": {
        "id": "dUstTUicOfLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)\n",
        "\n",
        "def iou_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    union = K.sum(y_true_f) + K.sum(y_pred_f) - intersection\n",
        "    return (intersection + 1) / (union + 1)\n",
        "\n",
        "# Calculate on the test set\n",
        "# Note: We use the raw predictions (probabilities), not the thresholded ones, for smoother calculation\n",
        "results = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Standard Accuracy: {results[1]*100:.2f}%\")\n",
        "\n",
        "# Calculate specific Dice/IoU\n",
        "predictions = model.predict(X_test, verbose=0)\n",
        "dice = dice_coef(tf.cast(y_test, tf.float32), tf.cast(predictions, tf.float32))\n",
        "iou = iou_coef(tf.cast(y_test, tf.float32), tf.cast(predictions, tf.float32))\n",
        "\n",
        "print(f\"Dice Score (Overlap Accuracy): {dice.numpy():.4f}\")\n",
        "print(f\"IoU Score (Intersection over Union): {iou.numpy():.4f}\")"
      ],
      "metadata": {
        "id": "4WJwFcuhOgI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test on a Single New Image (Simulation)\n",
        "Imagine you are a doctor and you just took a new ultrasound. You want to see if the AI can handle a raw image that it has never seen before (and that doesn't have a mask yet)."
      ],
      "metadata": {
        "id": "43EEZ_eaOwCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from PIL import Image\n",
        "\n",
        "print(\"Upload a new ultrasound image (png/jpg):\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "    # 1. Load the image\n",
        "    img = Image.open(fn).convert('RGB') # Ensure it's 3 channels\n",
        "    img = img.resize((128, 128))\n",
        "    img_array = np.array(img) / 255.0  # Normalize\n",
        "    img_input = np.expand_dims(img_array, axis=0) # Add batch dimension (1, 128, 128, 3)\n",
        "\n",
        "    # 2. Predict\n",
        "    prediction = model.predict(img_input)\n",
        "    prediction_mask = (prediction > 0.5).astype(np.uint8)\n",
        "\n",
        "    # 3. Plot\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img_array)\n",
        "    plt.title(\"Uploaded Image\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(prediction_mask[0, :, :, 0], cmap='gray')\n",
        "    plt.title(\"AI Generated Mask\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "gsCTHQfDOzjZ",
        "outputId": "c9e767a3-f2ed-49f5-af3d-e431ef7cfa81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'NoneType' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1009979966.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Upload a new ultrasound image (png/jpg):\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     result = _output.eval_js(\n\u001b[1;32m    173\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    }
  ]
}